# Обзор Проекта по Созданию ИИ-Агента для Трейдинга

## 1. Главная Цель Проекта

Основная цель этого проекта — создать **гибридного ИИ-агента для трейдинга**. "Гибридный" означает, что он сочетает в себе два подхода:
1.  **Человеческий опыт:** Использование проверенных временем стандартных технических индикаторов.
2.  **Машинный анализ:** Использование кастомных индикаторов, основанных на анализе микроструктуры рынка, и применение **генетического программирования** для автоматического "изобретения" новых, более эффективных индикаторов.

## 2. Ключевая Философия: "Направляемая Эволюция"

Мы не строим "черный ящик" с нуля. Вместо этого мы придерживаемся стратегии **"Направляемой Эволюции"**:
- Мы даем ИИ-алгоритму (генетическому) "намеки" в виде набора качественных, заранее отобранных индикаторов (как "человеческих", так и кастомных).
- Алгоритм использует эти индикаторы как "гены" или "строительные блоки".
- В процессе эволюции он скрещивает, мутирует и комбинирует их, чтобы найти новые, более сильные гибридные индикаторы, которые человек, возможно, никогда бы не придумал. Например: `(Сила Поглощения / RSI) * VWAP_distance`.

## 3. Архитектура Проекта

Для надежности и масштабируемости весь процесс подготовки данных разделен на **два независимых этапа**:

### Этап 1: Экспорт "Сырых" Данных в CSV

- **Задача:** Безопасно и с минимальным потреблением памяти выгрузить большие объемы исторических данных из базы данных PostgreSQL в локальные CSV-файлы.
- **Инструмент:** `export_to_csv.py`
- **Как использовать:** Запустить скрипт `export_to_csv.sh`, предварительно настроив в нем желаемый символ и период.
- **Результат:** Папка `raw_data` с файлами `*_trades.csv`, `*_depth.csv`, `*_liquidations.csv`.

### Этап 2: Расчет Индикаторов и Создание Финального Датасета

- **Задача:** Взять "сырые" CSV-файлы, рассчитать на их основе все индикаторы и создать единый, готовый для обучения модели датасет.
- **Инструмент:** `prepare_dataset.py`
- **Как использовать:** Запустить скрипт `prepare_dataset.sh`. Он проверит наличие файлов, созданных на Этапе 1, и обработает их.
- **Результат:** Один файл `features.parquet`, содержащий все рассчитанные признаки.

**Ключевая особенность:** Внутри этого скрипта реализована важная логика:
1.  Сырые тиковые данные агрегируются в **1-минутные свечи (бары)**.
2.  "Человеческие" индикаторы (EMA, RSI и т.д.) рассчитываются на этих минутных барах, что является методологически правильным.
3.  Кастомные "AI-driven" индикаторы рассчитываются на исходных тиковых данных.
4.  Два набора признаков объединяются, обогащая каждую сделку контекстом с более крупного таймфрейма.

## 4. Набор Признаков (Индикаторов)

Финальный датасет `features.parquet` содержит два типа признаков:

#### А. "Человеческие" (рассчитаны на 1-минутных барах)
- `EMA (9, 21)`: Определение краткосрочного тренда.
- `VWAP`: Определение "центра гравитации" цены.
- `RSI (7)`: Оценка "перегретости" рынка.
- `Bollinger Bands (20, 2)`: Оценка текущей волатильности.

#### Б. Кастомные "AI-driven" (рассчитаны на тиковых данных)
- `Order Flow Delta`: Соотношение агрессивных покупок и продаж.
- `Absorption Strength`: Сила поглощения ликвидности.
- `Crowd Panic Index`: Уровень паники/эйфории на рынке.
- `Order Book Imbalance`: Дисбаланс в стакане.
- `Liquidity Walls`: Расстояние до крупных стенок ликвидности.
- `Footprint Imbalance`: Микро-дисбаланс внутри потока сделок.
- `Cascade Exhaustion`: Скорость затухания ликвидаций.

## 5. Этап 2: Эксперименты с Генетическим Программированием

- **Задача:** Использовать созданный `features.parquet` для поиска новых, более сильных гибридных индикаторов.
- **Инструмент:** `find_genetic_feature.py`
- **Как использовать:** `python backtester/find_genetic_feature.py --dataset features.parquet`
- **Что делает:** Этот скрипт является инструментом для исследований. Он загружает датасет, обучает базовую модель, а затем с помощью `gplearn` пытается "изобрести" новую формулу, которая улучшит качество предсказаний.

## 6. Пошаговый План Работы с Проектом

1.  **Настроить `.env`:** Указать правильные данные для подключения к вашей базе данных PostgreSQL в файле `.env`.
2.  **Выгрузить сырые данные:** При необходимости изменить параметры (символ, даты) в `export_to_csv.sh` и запустить его: `bash export_to_csv.sh`.
3.  **Создать датасет с признаками:** Запустить `prepare_dataset.sh`: `bash prepare_dataset.sh`.
4.  **Экспериментировать:** Запустить `find_genetic_feature.py`, указав ему путь к созданному файлу `features.parquet`, чтобы начать поиск новых индикаторов.

## 7. Следующие Шаги (Будущее Развитие)

- **Развитие генетического алгоритма:** Модифицировать `find_genetic_feature.py` для реализации полноценной стратегии "Направляемой Эволюции" (использование существующих индикаторов как "затравки", поиск не одного, а целого портфеля индикаторов).
- **Создание модели:** Написать скрипт для обучения предсказательной модели (например, `LightGBM` или нейронной сети) на файле `features.parquet`.
- **Бэктестинг:** Реализовать систему для проверки прибыльности стратегии на исторических данных.
- **Live Trading:** Создать агента для торговли в реальном времени на основе обученной модели.
